# -*- coding: utf-8 -*-
"""Preprocessing and WordClouds For Traditionally-Male Dominated and Traditionally-Female Dominated Jobs

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pd7Eieiz7aE1jj2AYWEKqrHnAKpF5yMW

## Preprocessing and WordClouds For Traditionally-Male Dominated and Traditionally-Female Dominated Jobs

Berra Karayel
0054477

### Loading the data
"""

import pandas as pd
import os

ads_categorized = pd.read_csv("/content/linkedin-sentiment-data-annotatedd.csv")
ads_categorized.head()

print(ads_categorized.dtypes)

ads_categorized["Category"]= ads_categorized["Category"].astype("string")

print(ads_categorized.dtypes)

"""### Preprocessing and Cleaning the Data"""

ads_categorized = ads_categorized.dropna()

# Removing the columns
ads_categorized = ads_categorized.drop(columns=['Sentiment', 'Ad Number'], axis=1)

# Print out the first rows of job ads
ads_categorized.head()

import re

# Convert the titles to lowercase

ads_categorized["Category_processed"] = \
ads_categorized["Category"].map(lambda x: x.lower())

# Removing punctuation

ads_categorized["Category_processed"] = \
ads_categorized["Category"].map(lambda x: re.sub('[,\.!?]', '', x))

# Print out the first rows of job ads
ads_categorized["Category_processed"].head()

"""### Exploratory Analysis"""

# Import the wordcloud library
from wordcloud import WordCloud

# Join the different processed titles together.
category_wordcloud = ','.join(list(ads_categorized["Category_processed"].values))

# Create a WordCloud object
wordcloud = WordCloud(background_color="white", max_words=1000, contour_width=3, contour_color='steelblue')

# Generate a word cloud
wordcloud.generate(category_wordcloud)

# Visualize the word cloud
wordcloud.to_image()

female_dominated = ads_categorized.loc[ads_categorized["Domination"] == "female-dominated"]

female_dominated

# Import the wordcloud library
from wordcloud import WordCloud

# Join the different processed titles together.
category_wordcloud = ','.join(list(female_dominated["Requirements"].values))

# Create a WordCloud object
wordcloud = WordCloud(background_color="white", max_words=1000, contour_width=3, contour_color='steelblue')

# Generate a word cloud
wordcloud.generate(category_wordcloud)

# Visualize the word cloud
wordcloud.to_image()

male_dominated = ads_categorized.loc[ads_categorized["Domination"] == "male-dominated"]

male_dominated

# Import the wordcloud library
from wordcloud import WordCloud

# Join the different processed titles together.
category_wordcloud = ','.join(list(male_dominated["Requirements"].values))

# Create a WordCloud object
wordcloud = WordCloud(background_color="white", max_words=1000, contour_width=3, contour_color='steelblue')

# Generate a word cloud
wordcloud.generate(category_wordcloud)

# Visualize the word cloud
wordcloud.to_image()

"""## Zemberek
Tokenization
"""

!pip install antlr4-python3-runtime==4.8
!pip install zemberek-python

pip install zemberek-python

import time
import logging

from zemberek import (TurkishSpellChecker, TurkishSentenceNormalizer, TurkishSentenceExtractor, TurkishMorphology, TurkishTokenizer)

logger = logging.getLogger(__name__)

morphology = TurkishMorphology.create_with_defaults()
normalizer = TurkishSentenceNormalizer(morphology)
extractor = TurkishSentenceExtractor()

"""Sentence Normalization"""

def normalize_long_text(text):
    normalized_sentences = [normalizer.normalize(word) for word in text]
    normalized_text = " ".join(normalized_sentences)
    return normalized_text



"""Stop Words"""

import nltk

nltk.download('stopwords')

from nltk.corpus import stopwords
import re
stops = set(stopwords.words('turkish'))
print(stops)

splitted_words = []
for sent in new_sent:
    words = sent.split()
    splitted_words.append(words)

clean_sent = []
for sentence in splitted_words:
    new_sentence = [w for w in sentence if w not in stops]
    clean_sent.append(new_sentence)

"""Lemmatization"""

for token in clean_sent:
    j = 0
    for word in token:
        new_word = word.replace('"', '').replace("’", '').replace("'", '').replace("”", '')
        token[j] = new_word
        j += 1

import nltk
nltk.download()

nltk.download('punkt')

pip install zeyrek

import zeyrek
 analyzer = zeyrek.MorphAnalyzer()

lem_sent = []
for sent in clean_sent:
    normalized_sent = []
    for word in sent:
        if word == '':
            continue
        else:
            lem_word = analyzer.lemmatize(word)
            normalized_sent.append(lem_word[0][1[0]])
    lem_sent.append(normalized_sent)

x = lem_sent.copy()
for sent in x:
    i = 0
    for token in sent:
        sent[i] = token.lower()
        i += 1
lem_sent = x

lem_sent = list(filter(('').__ne__, lem_sent))

ads_categorized["Requirements"].head(5)

import numpy as np

ads_categorized['Requirements'].series = lem_sent
ads_categorized['Requirements'].head()

ads_categorized['Requirements'] = ads_categorized.Requirements.apply(' '.join)

ads_categorized['Requirements'].to_csv("lemmatized_ads_categorized.csv")

"""### Creating WordClouds

"""

from wordcloud import WordCloud, STOPWORDS

def creat_wordcloud(tweets):
    comment_words = ''
    stopwords = set(STOPWORDS)
    
    # iterate through the csv file
    for val in tweets:

        # typecaste each val to string
        val = str(val)

        # split the value
        tokens = val.split()

        # Converts each token into lowercase
        for i in range(len(tokens)):
            tokens[i] = tokens[i].lower()

        comment_words += " ".join(tokens)+" "

    wordcloud = WordCloud(width = 1200, height = 800,
                    background_color ='white',
                    max_words=3000,
                    stopwords = stopwords,
                    min_font_size = 10,
                    repeat = True).generate(comment_words)

    # plot the WordCloud image                       
    plt.figure(figsize = (8, 8), facecolor = None)
    plt.imshow(wordcloud)
    plt.axis("off")
    plt.tight_layout(pad = 0)

    plt.show()

ads_lemmatized = pd.read_csv("/content/ads_preprocessed.csv")
ads_lemmatized.head(5)

# All Data Set
category_wordcloud = ','.join(list(ads_lemmatized["Requirements_processed"].values))
wordcloud = WordCloud(background_color="white", max_words=1000, contour_width=3, contour_color='steelblue')
wordcloud.generate(category_wordcloud)
wordcloud.to_image()

female_dominated_ads = pd.read_csv("/content/female dominated job ads.csv")
female_dominated_ads.head()

# Mostly Occurred Keywords in Traditionally-Female-Dominated Job Ads
category_wordcloud = ','.join(list(female_dominated_ads["Requirements_processed"].values))
wordcloud = WordCloud(background_color="white", max_words=1000, contour_width=3, contour_color='steelblue')
wordcloud.generate(category_wordcloud)
wordcloud.to_image()

male_dominated_ads = pd.read_csv("/content/male dominated ads.csv")
male_dominated_ads.head()

# Mostly Occurred Keywords in Traditionally-Male-Dominated Job Ads
category_wordcloud = ','.join(list(male_dominated_ads["Requirements_processed"].values))
wordcloud = WordCloud(background_color="white", max_words=1000, contour_width=3, contour_color='steelblue')
wordcloud.generate(category_wordcloud)
wordcloud.to_image()